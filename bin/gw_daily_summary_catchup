#!/bin/bash -l

#
# LIGO daily summary page script
#
# Author: Duncan Macleod <duncan.macleod@ligo.org>
# Modified by: Max
#
# A pipeline is generated using the gw_summary_pipe DAG generator
# before this DAG is submitted to the condor job scheduler
#

. ~/.bash_profile

echo ${X509_USER_PROXY}

REPODIR=${HOME}/summary
CONFIGDIR=${REPODIR}/config
LOGDIR=${TMPDIR}/summary/logs
NODUSCONFIG=/cvs/cds/caltech/chans/GWsummaries
NODUSWEB=/users/public_html/detcharsummary

let YESTERDAY=$(lalapps_tconvert)-86400
DAY=`lalapps_tconvert -f %Y%m%d ${YESTERDAY}`

# MI: not sure what this does...
#if [ "${USER}" == "detchar" ]; then
#    unset X509_USER_PROXY
#fi

# refresh configurations
cd ${REPODIR}
git pull --rebase

rm -r ${CONFIGDIR}/*

# pull from nodus
scp -r controls@nodus.ligo.caltech.edu:${NODUSCONFIG}/* ${CONFIGDIR}/

# catch command line options
CLARGS=$@

# set frameCPP environment
export PYTHONPATH=${PYTHONPATH}:/usr/lib/python2.6/site-packages/framecpp:/usr/lib64/python2.6/site-packages/framecpp

# set LALSuite environment
LALSUITE_TAG=de671f
. /home/detchar/opt/lalsuite/${LALSUITE_TAG}/etc/lalsuiterc

# set GWpy environment
. /home/max.isi/.bashrc
#. /home/detchar/opt/gwpysoft/etc/gwpy-user-env.sh

echo "Environment set"

cleanpath PYTHONPATH
cleanpath PATH

# set kerberos environment
if [ "${USER}" == "max.isi" ]; then
    export KRB5CCNAME=${TMPDIR}/gw_summary_ligo.org.krb5
    LIGO_USER=max.isi
    export KRB5_KTNAME=${HOME}/.kerberos/max.isi.keytab
    kinit -kft ${KRB5_KTNAME} ${LIGO_USER}@LIGO.ORG 1> /dev/null
    if [ $? -eq 0 ]; then
        echo "Kerberos ticket generated for ${LIGO_USER}"
    else
        EC=$?
        echo "Failed to generate kerberos ticket"
        exit $?
    fi
fi
klist -s
if [ $? -eq 1 ]; then
    echo "gw_summary requires a kerberos ticket, please generate one and try again"
    exit 1
fi
set -e

# set output directory
RUN_DIRECTORY=$HOME/public_html/summary/
mkdir -p ${RUN_DIRECTORY}
# clean previous DAGs
{
  rm ${RUN_DIRECTORY}/gw_summary_catchup*
} || {
  echo "No previous DAGs."
}
# clean previous logs
{
  rm ${RUN_DIRECTORY}/logs/gw_summary_catchup*
} || {
  echo "No previous logs."
}
cd ${RUN_DIRECTORY}
echo "Moved to output directory ${RUN_DIRECTORY}"
echo "----------"

# interpolate IFO
if [[ "$(hostname -f)" == *"ligo-la"* ]]; then
    IFO="L1"
elif [[ "$(hostname -f)" == *"ligo-wa"* ]]; then
    IFO="H1"
elif [[ "$(hostname -f)" == *"ligo.caltech"* ]]; then
    IFO="C1"
elif [[ -z "${IFO}" ]]; then 
    echo "Cannot determine IFO, either give via '--ifo=X1' of set IFO environment variable" >&2
    exit 1
fi

ifo=$(echo $IFO | awk '{print tolower($0)}')

# set maximum number of processes per node
if [[ "${CLARGS}" == *"multi-process"* ]]; then
    MAXPROC=""
else
    MAXPROC="--multi-process 20"
fi

# set maxjobs
if [[ "${CLARGS}" == *"maxjobs"* ]]; then
    MAXJOBS=""
else
    MAXJOBS="--maxjobs 2"
fi

# set configuration
if [[ "${CLARGS}" == *"config-file"* ]]; then
    CONFIGARG=""
    PRIORITYARG=""
else
    # generate option string from files in configuration directory
    ${HOME}/summary/bin/configlist.py ${IFO}
    # load string into CONFIGARG variable
    PRIORITYARG=""
    CONFIGARG=$(<${TMPDIR}/summary/configstr.txt)
fi

# set arguments
DEFAULTCONFIG=${CONFIGDIR}/defaults.ini
UNIVERSE="local"
TIMEOUT="2"
OPTIONS="--archive --day ${DAY} --verbose --file-tag gw_summary_catchup --skip-html-wrapper --ifo ${IFO} --log-dir ${LOGDIR} --global-config ${DEFAULTCONFIG} ${CONFIGARG} ${PRIORITYARG} --universe ${UNIVERSE} --condor-timeout ${TIMEOUT} --on-segdb-error warn ${MAXPROC} ${MAXJOBS}"
ARGUMENTS=$(eval echo ${CLARGS})

# run job and capture DAGMan process ID
echo "Executing:"
echo
echo "gw_summary_pipe ${OPTIONS} ${ARGUMENTS}"
DAGFILE=$(basename $(gw_summary_pipe ${OPTIONS} ${ARGUMENTS} | tail -n1))
echo
echo "Dag generated as:"
echo
echo $DAGFILE
echo

if [ -f ${DAGFILE}.lock ]; then
    echo "DAG lock file already exists, cannot submit now!" 1>&2
    exit 1
fi

sleep 5
condor_submit_dag -force ${DAGFILE}
PID=$(pgrep -n condor_dagman)

echo "DAG submitted successfully, waiting on it to finish..."
sleep 2
while [ -f ${DAGFILE}.lock ]; do
    sleep 30
done

echo "DAG has exited"
if [ -f ${DAGFILE}.rescue001 ]; then
    echo "Something broke, the rescue DAG was generated." 1>&2
    echo "Changes not pushed to Nodus."
    exit 1
else
    echo "Summary page run complete!"
    # push to 40m
    rsync --exclude archive/ -r ${RUN_DIRECTORY}/ controls@nodus.ligo.caltech.edu:${NODUSWEB} 
    echo "Changes pushed to Nodus."
    exit 0
fi
